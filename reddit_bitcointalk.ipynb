{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8467e7-ed62-42e0-9b20-c4ebd9f8a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary library imports\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "import zlib\n",
    "import msgpack\n",
    "import tqdm\n",
    "import time\n",
    "import os.path\n",
    "# import helper_functions as hf\n",
    "# import io_helper as ioh\n",
    "# import files from src\n",
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32917ceb-5c23-48d2-bda9-2341f8357c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# define where we're going to save the data\n",
    "path_save_data = \"Project_2\"\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path_save_data)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist \n",
    "    os.makedirs(path_save_data)\n",
    "    print(\"The new directory is created!\")\n",
    "\n",
    "filename_save_data = \"{:s}/augmento_reddit_data.msgpack.zlib\".format(path_save_data)\n",
    "\n",
    "\n",
    "print(isExist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a84001f-6009-43ac-a3c1-c1cb3dde44a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got data from 2017-01-01T00:00:00Z to 2019-09-27T00:00:00Z\n",
      "got data from 2017-01-01T00:00:00Z to 2022-05-31T00:00:00Z\n",
      "got data from 2017-01-01T00:00:00Z to 2022-05-31T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "# define the url of the endpoint to get event data\n",
    "endpoint_url = \"http://api-dev.augmento.ai/v0.1/events/aggregated\"\n",
    "\n",
    "\n",
    "# define the start and end times\n",
    "datetime_start = datetime.datetime(2017, 1, 1)\n",
    "datetime_end = datetime.datetime(2022, 6, 1)\n",
    "\n",
    "# initialise a store for the data we're downloading\n",
    "sentiment_data = []\n",
    "\n",
    "# define a start pointer to track multiple requests\n",
    "start_ptr = 0\n",
    "count_ptr = 1000\n",
    "\n",
    "# get the data\n",
    "while start_ptr >= 0:\n",
    "\t\n",
    "\t# define the parameters of the request\n",
    "\tparams = {\n",
    "\t\t\"source\" : \"reddit\",\n",
    "\t\t\"coin\" : \"ethereum\",\n",
    "\t\t\"bin_size\" : \"24H\",\n",
    "\t\t\"count_ptr\" : count_ptr,\n",
    "\t\t\"start_ptr\" : start_ptr,\n",
    "\t\t\"start_datetime\" : datetime_start.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "\t\t\"end_datetime\" : datetime_end.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "\t}\n",
    "\t\n",
    "\t# make the request\n",
    "\tr = requests.request(\"GET\", endpoint_url, params=params)\n",
    "\t\n",
    "\t# if the request was ok, add the data and increment the start_ptr\n",
    "\t# else return an error\n",
    "\tif r.status_code == 200:\n",
    "\t\ttemp_data = r.json()\n",
    "\t\tstart_ptr += count_ptr\n",
    "\telse:\n",
    "\t\traise Exception(\"api call failed with status_code {:d}\".format(r.status_code))\n",
    "\t\n",
    "\t# if we didn't get any data, assume we've got all the data\n",
    "\tif len(temp_data) == 0:\n",
    "\t\tstart_ptr = -1\n",
    "\t\n",
    "\t# extend the data store\n",
    "\tsentiment_data.extend(temp_data)\n",
    "\t\n",
    "\t# print the progress\n",
    "\tstr_print = \"got data from {:s} to {:s}\".format(*(sentiment_data[0][\"datetime\"],\n",
    "\t                                                sentiment_data[-1][\"datetime\"],))\n",
    "\tprint(str_print)\n",
    "\t\n",
    "\t# sleep\n",
    "\ttime.sleep(.02)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd19a7f-ed3e-4ace-96af-7360d7cb04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to Project_2/augmento_reddit_data.msgpack.zlib\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# save the data\n",
    "print(\"saving data to {:s}\".format(filename_save_data))\n",
    "with open(filename_save_data, \"wb\") as f:\n",
    "\tf.write(zlib.compress(msgpack.packb(sentiment_data)))\n",
    "\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5cf76b3-efce-4b90-ac2b-d364bca5fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# define where we're going to save the data\n",
    "path_save_data = \"Project_2\"\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path_save_data)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist \n",
    "    os.makedirs(path_save_data)\n",
    "    print(\"The new directory is created!\")\n",
    "\n",
    "filename_save_data = \"{:s}/aug_bitcointalk_data.msgpack.zlib\".format(path_save_data)\n",
    "\n",
    "\n",
    "print(isExist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea340bd-7142-4bd2-9ceb-d1165c511bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got data from 2017-01-01T00:00:00Z to 2019-09-27T00:00:00Z\n",
      "got data from 2017-01-01T00:00:00Z to 2022-05-31T00:00:00Z\n",
      "got data from 2017-01-01T00:00:00Z to 2022-05-31T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "# define the url of the endpoint to get event data\n",
    "endpoint_url = \"http://api-dev.augmento.ai/v0.1/events/aggregated\"\n",
    "\n",
    "\n",
    "# define the start and end times\n",
    "datetime_start = datetime.datetime(2017, 1, 1)\n",
    "datetime_end = datetime.datetime(2022, 6, 1)\n",
    "\n",
    "# initialise a store for the data we're downloading\n",
    "sentiment_data = []\n",
    "\n",
    "# define a start pointer to track multiple requests\n",
    "start_ptr = 0\n",
    "count_ptr = 1000\n",
    "\n",
    "# get the data\n",
    "while start_ptr >= 0:\n",
    "\t\n",
    "\t# define the parameters of the request\n",
    "\tparams = {\n",
    "\t\t\"source\" : \"bitcointalk\",\n",
    "\t\t\"coin\" : \"ethereum\",\n",
    "\t\t\"bin_size\" : \"24H\",\n",
    "\t\t\"count_ptr\" : count_ptr,\n",
    "\t\t\"start_ptr\" : start_ptr,\n",
    "\t\t\"start_datetime\" : datetime_start.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "\t\t\"end_datetime\" : datetime_end.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "\t}\n",
    "\t\n",
    "\t# make the request\n",
    "\tr = requests.request(\"GET\", endpoint_url, params=params)\n",
    "\t\n",
    "\t# if the request was ok, add the data and increment the start_ptr\n",
    "\t# else return an error\n",
    "\tif r.status_code == 200:\n",
    "\t\ttemp_data = r.json()\n",
    "\t\tstart_ptr += count_ptr\n",
    "\telse:\n",
    "\t\traise Exception(\"api call failed with status_code {:d}\".format(r.status_code))\n",
    "\t\n",
    "\t# if we didn't get any data, assume we've got all the data\n",
    "\tif len(temp_data) == 0:\n",
    "\t\tstart_ptr = -1\n",
    "\t\n",
    "\t# extend the data store\n",
    "\tsentiment_data.extend(temp_data)\n",
    "\t\n",
    "\t# print the progress\n",
    "\tstr_print = \"got data from {:s} to {:s}\".format(*(sentiment_data[0][\"datetime\"],\n",
    "\t                                                sentiment_data[-1][\"datetime\"],))\n",
    "\tprint(str_print)\n",
    "\t\n",
    "\t# sleep\n",
    "\ttime.sleep(.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40bcc28-f4bb-46a9-a459-0cf1aacf873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to Project_2/aug_bitcointalk_data.msgpack.zlib\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# save the data\n",
    "print(\"saving data to {:s}\".format(filename_save_data))\n",
    "with open(filename_save_data, \"wb\") as f:\n",
    "\tf.write(zlib.compress(msgpack.packb(sentiment_data)))\n",
    "\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ced5f-9835-49ed-866f-931bb87e9fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
