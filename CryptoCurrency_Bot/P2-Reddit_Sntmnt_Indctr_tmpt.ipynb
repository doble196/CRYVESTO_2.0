{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20d9c91-c731-425e-813f-3bf0e97791c7",
   "metadata": {},
   "source": [
    "## Reddit Sentiment Indicator for Crypto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eb258-4e5a-4bbe-af45-2426f0325295",
   "metadata": {},
   "source": [
    "In this tutorial I will explain how to build a Reddit crypto currency sentiment indicator in Python. Sentiment analysis is the process of statistically determining if a piece of text is positive, negative or neutral. This program will scan Reddit for different crypto currencies and rank the keywords that are used in comments. Then it will determine if the sentiment is positive or negative.\n",
    "\n",
    "The process will:\n",
    "1. Fetch the latest crypto tickers from CoinGecko\n",
    "2. Search Reddit for these crypto tickers\n",
    "3. 'VADER' (a sentiment analysis) will check keywords in comments to determine if they are in a keyword lexicon (dictionary)\n",
    "4. Keywords identified in the lexicon will be graded as positive or negative\n",
    "5. Positive words have higher positive ratings and more negative words have lower negative ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb4cf2-cd40-49d7-9570-25a22011eb2c",
   "metadata": {},
   "source": [
    "### Reddit Sentiment Process \n",
    "- Configure Python code\n",
    "- Run code to generate sentiment analysis\n",
    "- Review results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19efa9-a965-464c-af0a-7ecbb3ba8735",
   "metadata": {},
   "source": [
    "### Python code to create sentiment analysis\n",
    "First create a Python file and name it `sentiment_reddit_template.py`. Copy the code below into this file. This template file creates the configuration file needed for sentiment analysis. In this file modify the black list and new words list.\n",
    "\n",
    "- blacklist = This is an exclusion list of items that you do not want to include in your analysis\n",
    "- new_words = This list contains the words you want to rank and their sentiment. Positive numbers represent a positive sentiment and negative numbers represent a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdc8aa-a160-4bca-b44f-2f3c84eecec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_reddit_template.py\n",
    "# use this template to generate the reddit sentiment config file which is used in the sentiment process\n",
    "crypto = { {{ tickers }} }\n",
    "\n",
    "# Exclude common words used on crypto reddit that are also crypto names\n",
    "blacklist = {'I', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR','DEC', 'BE', 'IMO', 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO', 'DD', 'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD', 'TYS', 'US', 'USA', 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', 'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY', 'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR', 'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO', 'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH', 'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA', 'USD', 'CPU', 'AT', 'GG', 'Mar'}\n",
    "\n",
    "\n",
    "# adding crypto reddit to vader to improve sentiment analysis, score: 4.0 to -4.0. Rank each keyword\n",
    "# add new key words below that you would like to rank\n",
    "\n",
    "new_words = {\n",
    "    'lambo': 4.0,\n",
    "    'rekt': -4.0,\n",
    "    'citron': -4.0,\n",
    "    'hidenburg': -4.0,\n",
    "    'moon': 4.0,\n",
    "    'Elon': 2.0,\n",
    "    'hodl': 2.0,\n",
    "    'highs': 2.0,\n",
    "    'mooning': 4.0,\n",
    "    'long': 2.0,\n",
    "    'short': -2.0,\n",
    "    'call': 4.0,\n",
    "    'calls': 4.0,\n",
    "    'put': -4.0,\n",
    "    'puts': -4.0,\n",
    "    'break': 2.0,\n",
    "    'tendie': 2.0,\n",
    "    'tendies': 2.0,\n",
    "    'town': 2.0,\n",
    "    'overvalued': -3.0,\n",
    "    'undervalued': 3.0,\n",
    "    'buy': 4.0,\n",
    "    'sell': -4.0,\n",
    "    'gone': -1.0,\n",
    "    'gtfo': -1.7,\n",
    "    'fomo': 2.0,\n",
    "    'paper': -1.7,\n",
    "    'bullish': 3.7,\n",
    "    'bearish': -3.7,\n",
    "    'bagholder': -1.7,\n",
    "    'stonk': 1.9,\n",
    "    'green': 1.9,\n",
    "    'money': 1.2,\n",
    "    'print': 2.2,\n",
    "    'rocket': 2.2,\n",
    "    'bull': 2.9,\n",
    "    'bear': -2.9,\n",
    "    'pumping': 1.0,\n",
    "    'sus': -3.0,\n",
    "    'offering': -2.3,\n",
    "    'rip': -4.0,\n",
    "    'downgrade': -3.0,\n",
    "    'upgrade': 3.0,\n",
    "    'maintain': 1.0,\n",
    "    'pump': 1.9,\n",
    "    'hot': 2,\n",
    "    'drop': -2.5,\n",
    "    'rebound': 1.5,\n",
    "    'crack': 2.5, }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bfaeeb-662d-4504-8cd4-5d6a52c57482",
   "metadata": {},
   "source": [
    "Second create a file called `sentiment_reddit_ticker_generator.py`. Copy the code below into this file. Use the code below to query Coin Gecko to get the latest list of tickers. This file will use the code above to generate the actual configuration file (`sentiment_reddit_config.py`) needed for the sentiment program. This process allows you to for update the ticker list on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5b01a-db35-4fa5-ae9a-aeba3dfbe06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "tickers = ''\n",
    "for i in range(1, 3):\n",
    "    # 250 tickets per page.  we are going to request 10 pages from Coingecko so that is 2,500 tickers\n",
    "    endpoint = f'https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd&order=market_cap_desc&per_page=250&page={i}&sparkline=false'\n",
    "\n",
    "    with urllib.request.urlopen(endpoint) as url:\n",
    "        # convert to a json\n",
    "        data = json.loads(url.read().decode())\n",
    "        for crypto in data:\n",
    "            tickers = tickers + \"'\" + crypto['symbol'].upper() + \"'\" + ','\n",
    "file_loader = FileSystemLoader('./')\n",
    "env = Environment(loader=file_loader)\n",
    "# dynamically create a file of tickers using the template file so it is in the correct format for the program\n",
    "template = env.get_template('sentiment_reddit_template.py')\n",
    "output = template.render(tickers=tickers)\n",
    "# save the results in sentiment_reddit_config.py\n",
    "with open(\"sentiment_reddit_config.py\", \"w\") as fh:\n",
    "    fh.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6164c7ae-c73f-4166-9529-cf621c3a0483",
   "metadata": {},
   "source": [
    "The code above will generate the actual configuration file named `sentiment_reddit_config.py`. This configuration file is used by the sentiment analysis process. It will contain the latest list of crypto tickers from Coin Gecko and sentiment words to rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2cf00-2440-417a-a1f8-53ffa8116e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all crypto tickers fetched from coingecko\n",
    "# this config file is used in the sentiment process\n",
    "crypto = { 'BTC','ETH','BNB','XRP','USDT','ADA','DOGE','DOT','UNI','LTC','BCH','LINK','VET','USDC','XLM','SOL','THETA','FIL','TRX','WBTC','BUSD','XMR','LUNA','NEO','KLAY','MIOTA','EOS','AAVE','CAKE','ATOM','BSV','CRO','BTT','OKB','FTT','MATIC','ETC','CUSDC','CETH','XTZ','MKR','ALGO','AVAX','KSM','DAI','RUNE','CDAI','HT','COMP','EGLD','XEM','HOT','DASH','CHZ','DCR','ZEC','SNX','ZIL','HBAR','STX','ENJ','CEL','LEO','SUSHI','AMP','WAVES','NEXO','SC','UST','DGB','GRT','FEI','NEAR','BAT','MANA','YFI','BTG','ARRR','UMA','QTUM','HBTC','RVN','LUSD','ONT','ZRX','ICX','HNT','ONE','ZEN','WRX','AR','FTM','FLOW','BNT','IOST','RSR','OMI','XDC','DENT','NANO','CHSB','PAX','ANKR','WIN','OMG','KCS','VGX','PUNDIX','CRV','XSUSHI','HUSD','CFX','XVG','BCHA','NPXS','1INCH','REN','XVS','LSK','NXM','LPT','VTHO','SNT','OXY','LRC','STETH','BTMX','CKB','RENBTC','BAL','GT','MIR','OCEAN','BOT','CELO','ZKS','CUSDT','TRIBE','BTCST','QNT','RAY','AXS','SRM','EWT','BAND','REEF','GLM','WOO','STMX','NKN','CUNI','KNCL','BCD','MAID','TON','FET','OGN','TLM','DODO','MED','SKL','AMPL','ARDR','KIN','TEL','CELR','ETN','HBC','AGI','NMR','SAND','WAXP','AUDIO','SXP','ALPHA','RFOX','CVC','MDX','ORN','BAKE','STEEM','FUN','KMD','POLY','TUSD','ARK','BTM','BTS','NOIA','ORBS','META','IOTX','ANT','USDN','AKT','SETH','KAVA','KLV','STORJ','RPL','XHV','GNO','GHX','WAN','ANC','VLX','SWAP','ERSDL','BADGER','UOS','FORTH','AVA','UBT','UQC','ALCX','HNS','COTI','NWC','MTL','LEND','SFP','HIVE','TITAN','RDD','HTR','RUNE','MATH','UTK','INJ','VRA','PAID','REP','KAI','BUNNY','KOBE','IQ','ROSE','LINA','MONA','TWT','RIF','KEEP','ELF','DNT','STRAX','SCRT','SUPER','ZMT','OHM','TRAC','GAS','POLS','CZRX','RLC','QKC','SYS','SUSD','TKO','CTSI','CRU','MASK','WNXM','CRE','ATRI','PERP','POWR','TOMO','ERN','XOR','PPT','JST','ROOK','VAI','VRSC','ALICE','EPS','FX','MFT','DAG','AION','PHA','EXRD','EDG','ADX','NU','DIA','RGT','API3','LAMB','PRQ','CBAT','LIT','LYXE','BCN','STETH','AE','GALA','DPI','IRIS','RNDR','SHR','DDX','ELA','PAC','HXRO','MLN','GNY','XAUT','RAMP','LTO','POND','C20','DAO','XCM','CHR','TRB','TT','ERG','AKRO','MAPS','FIRO','AUCTION','ZNN','MX','QUICK','EMC2','NMX','NRG','LOOMOLD','BSCPAD','DIVI','LON','NULS','IGNIS','DSLA','KDA','WOZX','SRK','CTK','ALBT','BEL','BOA','BAR','LBC','USDP','BEAM','MXC','HOGE','VSP','FREE','DUCK','FRAX','SFI','SOLVE','BLZ','COL','SPI','RFR','SERO','RLY','GRS','ID','LOC','ALPACA','PSG','GUSD','BZRX','DATA','SAFEMARS','DRGN','TORN','OXEN','WICC','PAXG','PIVX','AETH','SURE','VITE','HARD','FARM','SLT','GET','REQ','BIFI','TVK','WHALE','YFII','PCX','OM','MRPH','AERGO','HYDRA','COS','DUSK','VSYS','NXS','STAKE','DERO','VXV','MHC','VTC','ARPA','YLD','SWTH','CHAIN','PNK','STPT','BFC','XPRT','APL','HC','YCC','RAI','PIB','TRU','LGO','ESD','NEST','CREAM','FRONT','PHB','SBTC','WOW','ARMOR','VAL','SUKU','RAD','VETH','FIDA','NIM','NRV','FEG','DEGO','LAYER','BOSON','FIO','BELT','IDEX','VISR','SPARTA','SWINGBY','PNT','NBR','ZERO','COPE','MITH','ZAI','FRM','CFI','PROM','FSN','DF','HELMET','DEXT','MTA','BAO','CND','AST','BMI','FXF','ECO','HAI','HEGIC','DG','CARDS','LQTY','KP3R','WING','RDN','AIOZ','RARI','DMT','TBTC','KYL','AUTO','MBL','DCN','BONDLY','FIS','BIP','NFTX','SKY','BDPI','FXS','NXT','BOR','GXC','UFT','RING','DOCK','CORE','INDEX','VID','DEXE','CONV','RCN','SBD','UNFI','GBYTE','ZEE', }\n",
    "\n",
    "# Excludes common words and words used on crypto reddit that are also crypto names\n",
    "blacklist = {'I', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR','DEC', 'BE', 'IMO', 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO', 'DD', 'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD', 'TYS', 'US', 'USA', 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', 'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY', 'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR', 'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO', 'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH', 'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA', 'USD', 'CPU', 'AT', 'GG', 'Mar'}\n",
    "\n",
    "\n",
    "# adding crypto reddit to vader to improve sentiment analysis, score: 4.0 to -4.0. Rank each keyword\n",
    "\n",
    "new_words = {\n",
    "    'lambo': 4.0,\n",
    "    'rekt': -4.0,\n",
    "    'citron': -4.0,\n",
    "    'hidenburg': -4.0,\n",
    "    'moon': 4.0,\n",
    "    'Elon': 2.0,\n",
    "    'hodl': 2.0,\n",
    "    'highs': 2.0,\n",
    "    'mooning': 4.0,\n",
    "    'long': 2.0,\n",
    "    'short': -2.0,\n",
    "    'call': 4.0,\n",
    "    'calls': 4.0,\n",
    "    'put': -4.0,\n",
    "    'puts': -4.0,\n",
    "    'break': 2.0,\n",
    "    'tendie': 2.0,\n",
    "    'tendies': 2.0,\n",
    "    'town': 2.0,\n",
    "    'overvalued': -3.0,\n",
    "    'undervalued': 3.0,\n",
    "    'buy': 4.0,\n",
    "    'sell': -4.0,\n",
    "    'gone': -1.0,\n",
    "    'gtfo': -1.7,\n",
    "    'fomo': 2.0,\n",
    "    'paper': -1.7,\n",
    "    'bullish': 3.7,\n",
    "    'bearish': -3.7,\n",
    "    'bagholder': -1.7,\n",
    "    'stonk': 1.9,\n",
    "    'green': 1.9,\n",
    "    'money': 1.2,\n",
    "    'print': 2.2,\n",
    "    'rocket': 2.2,\n",
    "    'bull': 2.9,\n",
    "    'bear': -2.9,\n",
    "    'pumping': 1.0,\n",
    "    'sus': -3.0,\n",
    "    'offering': -2.3,\n",
    "    'rip': -4.0,\n",
    "    'downgrade': -3.0,\n",
    "    'upgrade': 3.0,\n",
    "    'maintain': 1.0,\n",
    "    'pump': 1.9,\n",
    "    'hot': 2,\n",
    "    'drop': -2.5,\n",
    "    'rebound': 1.5,\n",
    "    'crack': 2.5, } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb30a65-d944-4a11-a48a-34b0c64f7f3c",
   "metadata": {},
   "source": [
    "Finally, create a file called `sentiment_reddit.py`. Copy the code below into this file. This file will scan Reddit and use the configuration file above to generate sentiment data. Log into your Reddit account and retrieve your client id and client secret. This will enable the program to log into reddit programmatically and scan subReddits for information.\n",
    "\n",
    "- client_id=”xxxxxxxxxxxxxxxxxxxxxxx”,\n",
    "- client_secret=”xxxxxxxxxxxxxxxxxxxxxxx”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8302621-ba3b-4903-af4f-e34283d85743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import time\n",
    "import pandas as pd\n",
    "import logging\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "from sentiment_reddit_config import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "\n",
    "\n",
    "'''*****************************************************************************\n",
    "This program uses Vader SentimentIntensityAnalyzer to calculate a ticker/token compound value.\n",
    "Limitations:\n",
    "It depends mainly on the defined parameters for current implementation:\n",
    "It completely ignores the heavily down voted comments, and there can be a time when\n",
    "the most mentioned ticker is heavily down voted, but you can change that in upvotes variable.\n",
    "****************************************************************************'''\n",
    "\n",
    "start_time = time.time()\n",
    "reddit = praw.Reddit(\n",
    "    user_agent=\"Comment Extraction\",\n",
    "\n",
    "# replace with information from your Reddit account\n",
    "\n",
    "    client_id=\"xxxxxxxxxxxxxxxxxxxxxx\",\n",
    "    client_secret=\"xxxxxxxxxxxxxxxxxxx\"\n",
    ")\n",
    "logging.info('logged into Reddit')\n",
    "print('logged into Reddit')\n",
    "\n",
    "\n",
    "def sentiment_reddit():\n",
    "    threading.Timer(300, sentiment_reddit).start()\n",
    "\n",
    "#    \n",
    "#\n",
    "# set the program parameters\n",
    "#\n",
    "#\n",
    "    subs = ['CryptoCurrency', 'CryptoMarkets', 'EthTrader', 'Investing', 'Crypto_General', 'Bitcoin', 'CryptoCurrencyTrading', 'Coinbase', 'wallstreetbets']  # sub-reddit to search\n",
    "    post_flairs = {'Daily Discussion', 'Weekend Discussion', 'Discussion'}  # posts flairs to search || None flair is automatically considered\n",
    "    goodAuth = {'AutoModerator'}  # authors whom comments are allowed more than once\n",
    "    uniqueCmt = True  # allow one comment per author per symbol\n",
    "    ignoreAuthP = {'example'}  # authors to ignore for posts\n",
    "    ignoreAuthC = {'example'}  # authors to ignore for comment\n",
    "    upvoteRatio = 0.70  # upvote ratio for post to be considered, 0.70 = 70%\n",
    "    ups = 20  # define # of up votes, post is considered if up votes exceed this #\n",
    "    limit = 10  # define the limit, comments 'replace more' limit\n",
    "    upvotes = 2  # define # of up votes, comment is considered if up votes exceed this #\n",
    "    picks = 200  # define # of picks here, prints as \"Top ## picks are:\"\n",
    "    picks_ayz = 200  # define # of picks for sentiment analysis\n",
    "\n",
    "    posts, count, c_analyzed, tickers, titles, a_comments = 0, 0, 0, {}, [], {}\n",
    "    cmt_auth = {}\n",
    "\n",
    "    for sub in subs:\n",
    "        subreddit = reddit.subreddit(sub)\n",
    "        hot_python = subreddit.hot()  # sorting posts by hot\n",
    "        # Extracting comments, symbols from subreddit\n",
    "        for submission in hot_python:\n",
    "            flair = submission.link_flair_text\n",
    "            author = submission.author\n",
    "\n",
    "            # checking: post up vote ratio # of up votes, post flair, and author\n",
    "            if submission.upvote_ratio >= upvoteRatio and submission.ups > ups and (\n",
    "                    flair in post_flairs or flair is None) and author not in ignoreAuthP:\n",
    "                submission.comment_sort = 'new'\n",
    "                comments = submission.comments\n",
    "                titles.append(submission.title)\n",
    "                posts += 1\n",
    "                submission.comments.replace_more(limit=limit)\n",
    "                for comment in comments:\n",
    "                    # try except for deleted account?\n",
    "                    try:\n",
    "                        auth = comment.author.name\n",
    "                    except:\n",
    "                        pass\n",
    "                    c_analyzed += 1\n",
    "\n",
    "                    # checking: comment up votes and author\n",
    "                    if comment.score > upvotes and auth not in ignoreAuthC:\n",
    "                        split = comment.body.split(\" \")\n",
    "                        for word in split:\n",
    "                            word = word.replace(\"$\", \"\")\n",
    "                            # upper = ticker, length of ticker <= 5, excluded words,\n",
    "                            if word.isupper() and len(word) <= 5 and word not in blacklist and word in crypto:\n",
    "\n",
    "                                # unique comments, try/except for key errors\n",
    "                                if uniqueCmt and auth not in goodAuth:\n",
    "                                    try:\n",
    "                                        if auth in cmt_auth[word]: break\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                                # counting tickers\n",
    "                                if word in tickers:\n",
    "                                    tickers[word] += 1\n",
    "                                    a_comments[word].append(comment.body)\n",
    "                                    cmt_auth[word].append(auth)\n",
    "                                    count += 1\n",
    "                                else:\n",
    "                                    tickers[word] = 1\n",
    "                                    cmt_auth[word] = [auth]\n",
    "                                    a_comments[word] = [comment.body]\n",
    "                                    count += 1\n",
    "\n",
    "                                # sorts the dictionary\n",
    "    symbols = dict(sorted(tickers.items(), key=lambda item: item[1], reverse=True))\n",
    "    top_picks = list(symbols.keys())[0:picks]\n",
    "    # time = (time.time() - start_time)\n",
    "\n",
    "    # print top picks\n",
    "    # print(\"It took {t:.2f} seconds to analyze {c} comments in {p} posts in {s} subreddits.\\n\".format(t=time, c=c_analyzed, p=posts, s=len(subs)))\n",
    "    print(\"Posts analyzed saved in titles\")\n",
    "    # for i in titles: print(i)  # prints the title of the posts analyzed\n",
    "    logging.info(top_picks)\n",
    "    print(f\"\\n{picks} most mentioned picks: \")\n",
    "    times = []\n",
    "    top = []\n",
    "    for i in top_picks:\n",
    "        print(f\"{i}: {symbols[i]}\")\n",
    "        times.append(symbols[i])\n",
    "        top.append(f\"{i}: {symbols[i]}\")\n",
    "\n",
    "    # Applying Sentiment Analysis\n",
    "    scores, s = {}, {}\n",
    "\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    # adding custom words from config\n",
    "    vader.lexicon.update(new_words)\n",
    "\n",
    "    picks_sentiment = list(symbols.keys())[0:picks_ayz]\n",
    "    for symbol in picks_sentiment:\n",
    "        stock_comments = a_comments[symbol]\n",
    "        for cmnt in stock_comments:\n",
    "            score = vader.polarity_scores(cmnt)\n",
    "            if symbol in s:\n",
    "                s[symbol][cmnt] = score\n",
    "            else:\n",
    "                s[symbol] = {cmnt: score}\n",
    "            if symbol in scores:\n",
    "                for key, _ in score.items():\n",
    "                    scores[symbol][key] += score[key]\n",
    "            else:\n",
    "                scores[symbol] = score\n",
    "\n",
    "        # calculating avg.\n",
    "        for key in score:\n",
    "            scores[symbol][key] = scores[symbol][key] / symbols[symbol]\n",
    "            scores[symbol][key] = \"{pol:.3f}\".format(pol=scores[symbol][key])\n",
    "\n",
    "    # printing sentiment analysis\n",
    "    print(f\"\\nSentiment analysis of top {picks_ayz} picks:\")\n",
    "    df = pd.DataFrame(scores)\n",
    "    df.index = ['Bearish', 'Neutral', 'Bullish', 'Total/Compound']\n",
    "    df = df.T\n",
    "    # log the dataframe\n",
    "    logging.info('dataframe head - {}'.format(df.to_string()))\n",
    "    print(df) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48409021-07b8-48b0-aa95-c5f1cbb34b85",
   "metadata": {},
   "source": [
    "### Improvements to the Python Reddit sentiment analysis\n",
    "Take this code to the next level and modify the script above to implement additional enhancements:\n",
    "\n",
    "- Generate a graph or report\n",
    "- Modify the code to place a trade on the Ethereum blockchain\n",
    "- email the data or make it visual on a website\n",
    "This code is for learning and entertainment purposes only. The code has not been audited and use at your own risk. Remember smart contracts are experimental and could contain bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abd0e7-f30f-4018-8968-6bd552b31886",
   "metadata": {},
   "source": [
    "[CryptoMarketpool RedditSentiment Indicator Tutorial](https://cryptomarketpool.com/reddit-sentiment-indicator-for-crypto-in-python/) resource article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576402ca-39f7-4d6e-b549-46161de3c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
